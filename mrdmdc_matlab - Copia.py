import numpy as np
import matplotlib.pyplot as plt
from numpy import dot, multiply, diag, power
from numpy import pi, exp, sin, cos
from numpy.linalg import inv, eig, pinv, solve
from scipy.linalg import svd, svdvals
from math import floor, ceil # python 3.x

import scipy.io

import matplotlib.pyplot as plt
import numpy as np
import scipy
import math

from sklearn.metrics import mean_squared_error
#from pydmd.plotter import plot_eigs

import numpy as np
import matplotlib.pyplot as plt
from numpy import dot, multiply, diag, power
from numpy import pi, exp, sin, cos
from numpy.linalg import inv, eig, pinv, solve
from scipy.linalg import svd, svdvals
from math import floor, ceil # python 3.x

import scipy.io

from pydmd import dmdc





## Scelta del dataset, se a valori complessi o reali
#D_mat = scipy.io.loadmat('real_eig_timeseries.mat')
#D_mat = scipy.io.loadmat('complex_eig_timeseries.mat')
D_mat = scipy.io.loadmat('XU_DMDc.mat')

## Trasformo il formato .mat in un Numpy Array
## Cambiare l'argomento di D_mat['xt'] in D_mat['X'] se si usa il dataset XU_DMDc.mat
D_mat_list = [[element for element in upperElement] for upperElement in D_mat['X']]
U_mat_list = [[element for element in upperElement] for upperElement in D_mat['U']]
D = np.array(D_mat_list)
U = np.array(U_mat_list)

D = D[:,:int(D.shape[1] * 0.25)]
U = U[:,:int(U.shape[1] * 0.25)]

colonne_desiderate = D.shape[1]

x = np.linspace(0, 40, 40)
t = np.linspace(0, colonne_desiderate, colonne_desiderate)


X = D[:,:-1]
Y = D[:,1:] 
U = U[:,:]






def make_plot(X, x=None, y=None, figsize=(12, 8), title=''):
    """
    Plot of the data X
    """
    plt.figure(figsize=figsize)
    plt.title(title)
    X = np.real(X)
    CS = plt.pcolor(x, y, X)
    cbar = plt.colorbar(CS)
    plt.xlabel('Delayed State')
    plt.ylabel('Time (minute)')
    plt.show()


make_plot(D.T, x=x, y=t, title = 'sistema originale')




'''per il training dobbiamo modificare il tempo che sarebbe le colonne'''

mod = -1
training_mode = 0.5
test_mode = 0.25
if (mod == 0):  #modalità training
    D_mode = D[:,:int((training_mode*colonne_desiderate))]
    U_mode = U[:,:int(training_mode*colonne_desiderate)]
elif (mod == 1):
    D_mode = D[:,:int(test_mode*colonne_desiderate)]
    U_mode = U[:,:int(test_mode*colonne_desiderate)]
elif (mod == -1):
    D_mode = D[:,:colonne_desiderate]
    U_mode = U[:,:colonne_desiderate]




dmdc0 = dmdc.DMDc(svd_rank=0) 


def mrdmdc(D, U, level=0, bin_num=0, offset=0, max_levels=20, max_cycles=1):
    """Compute the multi-resolution DMD on the dataset `D`, returning a list of nodes
    in the hierarchy. Each node represents a particular "time bin" (window in time) at
    a particular "level" of the recursion (time scale). The node is an object consisting
    of the various data structures generated by the DMD at its corresponding level and
    time bin. The `level`, `bin_num`, and `offset` parameters are for record keeping 
    during the recursion and should not be modified unless you know what you are doing.
    The `max_levels` parameter controls the maximum number of levels. The `max_cycles`
    parameter controls the maximum number of mode oscillations in any given time scale 
    that qualify as "slow". The `do_svht` parameter indicates whether or not to perform
    optimal singular value hard thresholding."""
     
    
    # 4 times nyquist limit to capture cycles                 ## per il teorema di nyquist, un segnale sinusoidale puo'
                                                              ## essere ricostruito senza perdere informazioni, fintanto che 
                                                              ## viene campionato ad una frequenza due volte o piu' maggiori
                                                              ## della frequenza massima. (valore tipico: 4 volte maggiori)
                
    nyq = 4 * max_cycles                                      ## nyq = 8 * 2

    

    bin_size = D.shape[1]                          ## bin_size equivale al numero di colonne (1600)


    if (bin_size) < (nyq):                                        ## bin_size(1600)<nyq(16)
        return []

    # extract subsamples 
    step = floor(bin_size / nyq) # max step size to capture cycles   ## floor è una funzione che approssima per difetto
                                                                     ## esempio floor(2.9) equivale a 2.
                                                                     ## in questo caso bin_size / nyq == 100 , quindi step=100
            
    _D = D[:,::(step)]                                           ## D[:,:] è uno slice assignment, in particolare D[:,::step]
                                                             ## considera i valori presi ogni step di tutte le righe e crea
                                                               ## una nuova matrice con solo i valori considerati.
    _U = U[:,::(step)]
    
         
    X = _D[:,:-1]                                              ## in X considera tutti i valori (di _D) escludendo l'ultima 
                                                               ## colonna.
    
    Y = _D[:,1:]                                               ## in Y considera tutti i valori (di _D) escludendo la prima 
                                                               ## colonna.
    D0 = _D[:,:]
    U0 = _U[:,:-1]   #DA CONTROLLARE SE FARE U[:,:-1]
    dmdc0.fit(D0,U0)

    '''
    mu = dmdc0.eigs
    Phi = dmdc0.modes

    parte per la filtrazione degli slow
    rho = max_cycles / bin_size                                ## frequenza di taglio rho definita come n° max di modi dinamici
                                                               ## classificati come "slow" diviso il numero di colonne della
                                                               ## matrice D.  2/1600=0.00125

    # consolidate slow eigenvalues (as boolean mask)
    slow = (np.abs(np.log(mu) / (2 * pi * step))) <= rho       ## ritorna il valore assoluto [abs()] del logaritmo di mu diviso
                                                               ## 2*pi greco*step, che deve essere minore o uguale a rho.
                                                               ## in questo caso [false false false false true true false]
        
    n = sum(slow) # number of slow modes                       ## il numero dei modi "slow" è dato dalla somma di slow.
                                                               ## in questo caso 2.

    # extract slow modes (perhaps empty)                       ## si estrae i modi "slow"
    dmdc0.__setattr__('eigs', mu[slow])                                               ## in mu salva solo gli autovalori "slow"
                                                               ## da 7 autovalori a 2 autovalori.

   
    dmdc0.modes = Phi[:,slow]                                          ## in phi salva solo i modi dinamici "slow"
                                                               ## phi.shape era (80,7) adesso è (80,2).
    '''
                                                               

    dato = dmdc0.reconstructed_data()




    node = type('Node', (object,), {})()
    node.level = level            # level of recursion
    node.bin_num = bin_num        # time bin number
    node.bin_size = bin_size      # time bin size
    node.start = offset           # starting index
    node.stop = offset + bin_size # stopping index
    node.step = step              # step size
    node.dato = dato

    node.mu = dmdc0.eigs
    node.phi = dmdc0.modes
    node.A = dmdc0._Atilde
    node.B = dmdc0.B
    node._B = dmdc0._B
    node.psi = dmdc0.dynamics
    #node.X = X
    
    nodes = [node]


    if level < max_levels:
        split = ceil(bin_size / 2) # where to split           ## ceil(x) approssima per eccesso x
        nodes += mrdmdc(
            D[:,:split],
            U[:,:split],
            level=level+1,
            bin_num=2*bin_num,
            offset=offset,
            max_levels=max_levels,
            max_cycles=max_cycles,
            )
        nodes += mrdmdc(
            D[:,split:],
            U[:,split:],     #aggiunta da alessandro
            level=level+1,
            bin_num=2*bin_num+1,
            offset=offset+split,
            max_levels=max_levels,
            max_cycles=max_cycles,
            )
    return nodes


nodes = mrdmdc(D_mode, U_mode)




def confronto(D, D_mrdmdc_ridimensionata):
    D0 = D[0,:]
    D_0 = D_mrdmdc_ridimensionata[0,:]
    
    plt.figure(figsize=(16, 6)) 

    plt.subplot(121)
    plt.title("Original system")
    plt.plot(D0.real.T)

    plt.subplot(122)
    plt.title("Reconstructed system")
    plt.plot(D_0.real.T)

    plt.show()

    '''
    plt.figure()
    error=np.array(D0) - np.array(D_0)
    plt.plot(t, error.real, 'b', label='Diff')
    plt.legend()
    plt.show()
    '''



#questa funzione serve per andare a plottare il grafico di D_mrdmdc sempre con le stesse dimensioni   (una matrice 40 : 4 la fa diventare 40 : 7160)
def dimensionamento(dataset):
    # Calcola il fattore di ripetizione per ogni colonna
    fattore_ripetizione = colonne_desiderate // dataset.shape[1]
    # Espandi le colonne della matrice
    matrice_finale = np.repeat(dataset, fattore_ripetizione, axis=1)
    # Riduci le colonne al numero desiderato
    matrice_finale = matrice_finale[:, :colonne_desiderate]
    
    return matrice_finale


for i in range(0,9):
    D_mrdmdc = np.hstack([n.dato for n in nodes if n.level == i])
    x = D_mrdmdc.shape[0]
    D_mrdmdc_ridimensionata = dimensionamento(D_mrdmdc)
    y = D_mrdmdc_ridimensionata.shape[1]
    x = np.linspace(0, x, x)
    y = np.linspace(0, y, y)
    #make_plot(D_mrdmdc_ridimensionata.T, x=x, y=y, title='levels 0-' + str(i), figsize=(7.5, 5))
    #confronto(D, D_mrdmdc_ridimensionata)



plt.figure(figsize=(16, 6))

plt.subplot(121)
plt.title("Original system")
plt.pcolor(D.real.T)
plt.colorbar()

plt.subplot(122)
plt.title("Reconstructed system")
plt.pcolor(D_mrdmdc_ridimensionata.real.T)
plt.colorbar()

plt.show()




def mean_squared_error(y_true, y_pred):
    """
    Funzione che calcola MSE.
    :param y_true: lista di numeri che rappresentano i valori reali
    :param y_pred: lista di numeri che rappresentano i valori predetti
    :restituisce: MSE
    """
    return np.mean(np.abs(np.array(y_pred) - np.array(y_true))**2)

def MAPE (Y_actual,Y_Predicted):   #MEAN ABSOLUTE PERCENTAGE ERROR
    mape = np.mean(np.abs((np.array(Y_actual) - np.array(Y_Predicted))/np.array(Y_actual)))*100
    return mape

def MAE(y_true, y_pred):     #MEAN ABSOLUTE ERROR
    mae_value = np.mean(np.abs(np.array(y_true) - np.array(y_pred)))
    return mae_value

def RMSE(y_true, y_pred):     #ROOT MEAN SQUARED ERROR
    rmse_value = np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))
    return rmse_value

from sklearn.metrics import r2_score
def R2(y_true, y_pred):
    r2_value = r2_score(np.array(y_true.real), np.array(y_pred.real))
    return r2_value


#D_mrdmdc_ridimensionata = dimensionamento(D_mrdmdc)

print("Errore MSE:")
print((mean_squared_error(D_mrdmdc_ridimensionata.T,D.T)))
print ("errore MAPE: ")
print (MAPE(D_mrdmdc_ridimensionata.T , D.T),"%")
print ("errore MAE: ")
print(MAE(D_mrdmdc_ridimensionata.T , D.T))
print ("errore RMSE: ")
print(RMSE(D_mrdmdc_ridimensionata.T , D.T))
print ("errore R2: ")
print(R2(D_mrdmdc_ridimensionata.T , D.T))



plt.figure()
plt.plot(t, D.real[0,:], 'b', label='Misura')
plt.plot(t, D_mrdmdc_ridimensionata.real[0,:], 'g', label='mrDMD')
plt.legend()
plt.show()

plt.figure()
error=np.array(D) - np.array(D_mrdmdc_ridimensionata)
plt.plot(t, error.real[0,:], 'b', label='Diff')
plt.legend()
plt.show()











